### OS

* 用户线程VS内核线程：用户线程创建销毁消耗少，不需要走内核（用户态和内核态的切换），不消耗内核线程资源（内核能创建的内核线程有限），但是内核不感知用户线程，一个用户线程的阻塞会导致整个进程的阻塞（一人有难，全家牵连），而且分到的时间片也会被分给所有的用户线程（多人只分到一块蛋糕）执行时间短

* dont repeat yourself

* User --> user cache --> page cache --> disk :一般的缓冲，非直接IO

* 直接IO：User --> user cache -->  disk  (不走内核缓冲page cache，直接调设备驱动)

  * https://cloud.tencent.com/developer/news/406991

* 阻塞 I/O：等待「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程

* 文件系统：http://c.biancheng.net/view/3066.html

* DMA（Direct Memory Access） 功能，它可以使得设备在 CPU 不参与的情况下，能够⾃⾏完成把设备 I/O 数据放⼊到内存. Cpu-->DMA-->device<-->memory

* 键盘键入字符的发生事情：键盘设备缓存字符，向cpu发起**硬件中断**，cpu响应中断，(DMA?)从键盘设备读取字符至内存，进入中断处理函数：**放到「读缓冲区队列」**，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」（如果有写文件操作，大概也是去读「读缓冲区队列」？），最后把「写缓冲 区队列」的数据⼀个⼀个写⼊到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕 ⾥。

* linux发送网络包过程：application --> socket发送缓冲区 --> 网络协议栈 -->网卡 ----------> 网卡 --> 网络协议栈 --> socket接收缓冲区 -->application

* 零拷贝：https://zhuanlan.zhihu.com/p/83398714

  * 在⾼并发的场景下，针对⼤⽂件的传输的⽅式，应该使⽤「异步 I/O + 直接 I/O」来替代零拷⻉技 术
  * 传输⽂件的时候，我们要根据⽂件的⼤⼩来使⽤不同的⽅式： 传输⼤⽂件的时候，使⽤「异步 I/O + 直接 I/O」； 传输⼩⽂件的时候，则使⽤「零拷⻉技术」

* 一致性hash：https://segmentfault.com/a/1190000021199728

* I/O 多路复⽤：

  * select

    * **最大限制：**单个进程能够监视的文件描述符的数量存在最大限制
    * **时间复杂度：** 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低，时间复杂度O(n)
    * **内存拷贝：**需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大
    * 阻塞式调用

  * poll

    * **没有最大连接数的限制**。（基于链表来存储的）
    * 其余同select

  * epoll

    * **没有最大连接数的限制**
    * **时间复杂度低：** 边缘触发和事件驱动，监听回调，时间复杂度O(1)。
    * **内存拷贝：**利用mmap()文件映射内存加速与内核空间的消息传递，减少拷贝开销。
    * **边缘触发：**只有**新数据**到来才触发
    * **⽔平触发：**只要有数据就触发
    * ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高

  * 多路复⽤ API 返回的事件并不⼀定可读写的，如果使⽤阻塞 I/O， 那么在调⽤ read/write 时则会发⽣程序阻塞，因此最好搭配**⾮阻塞 I/O**，以便应对极少数的特殊情况。

    > Under Linux, select() may report a socket file descriptor as "ready for reading", while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block.


* Reactor模型
  * **I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**。
  * Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
  * 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；
  * 单 Reactor 单进程 / 线程：**Redis**：EventLoop
    * 不适⽤计算机密集型的场景，只适⽤于业务处理⾮常快速的场景
    * 无锁
* 多 Reactor 多进程 / 线程
  * 主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept  获取连接，将新的连接分配给某个子线程；
  * 子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。
  * 如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。
  * Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。
  * 特点
    * 主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。
    * 主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。
* page cache：https://spongecaptain.cool/SimpleClearFileIO/1.%20page%20cache.html
* 申请内存：
  * 应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。
  * 当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生**缺页中断**，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。
* 虚拟内存作用
  * 第一，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间地址冲突的问题。
  * 第二，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。(包装一层)
* 内存回收
  * 回收策略
    * 后台内存回收：异步
    * 直接内存回收：同步
  * 回收对象
    * 文件页：文件
    * 匿名页：进程（栈，堆等
* 硬中断和软中断
  * 硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程，名字通常为「ksoftirqd/CPU 编号」，比如 0 号 CPU 对应的软中断内核线程的名字是 `ksoftirqd/0`
* 信号  https://os.51cto.com/article/675743.html
  * 信号的执行在该进程返回到用户模式时开始
* 线程的崩溃：内核发信号（例如：SIGSEGV非法访问）---> 信号处理函数（ ---> 退出）
  * 可通过自定义信号处理函数规避线程崩溃导致的进程崩溃

### Mysql

* 连接 --> 语法、词法解析 --> 优化器 --> 执行器 --> 存储引擎

* 预编译：mysql提前语法分析，将sql语句模板化或者说参数化
  * 优点：一次编译、多次运行，省去了解析优化等过程；此外预编译语句能防止sql注入

* 组提交机制

  * 秒杀中减轻mysql压力
  * mysql中redo log和binlog写盘时降低磁盘压力
  * singleflight

* crash safe

  * 依赖于redo log + binlog，利用两阶段提交确保一致性

* redo log作用

  * crash safe
  * 写数据库的时候，不用每次都刷盘，可以安心放在内存中（还是crash safe

* binlog格式：row（用的多，另外可以用于快速恢复）、statement

* mysql集群架构：一主一备多从

* 从库的并行复制

  * 经典策略：同库、同表、同行的放在一个worker中执行
  * MariaDB 的并行复制策略：能够在同一组里提交的事务，一定不会修改同一行；主库上可以并行执行的事务，备库上也一定是可以并行执行的。

* 主从延时导致的不一致

  * 强制走主库（取巧
  * sleep一段时间（取巧
  * GTID保证一致性

* 临时表

  * 一个临时表只能被创建它的 session 访问，对其他线程不可见，在 session 结束的时候，会自动删除

* Buffer pool

  * mysql用户态自定义，绕过操作系统的page cache，使用直接IO
  * Free 链表、LRU 链表、Flush 链表
  * 页面淘汰算法：分young区和old区的LRU算法

* WAL：

  * WAL （Write-Ahead Logging）技术，指的是 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上。
  * MySQL 的写操作从磁盘的「随机写」变成了「顺序写」

* 建立联合索引时，要把**区分度大**的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到。

* 不建索引的场景

  * where条件里不用的
  * 经常更新的字段

* 即使查询过程中，没有遵循最左匹配原则，某些sql查询也会走索引扫描的

  * MySQL 优化器认为直接遍历二级索引树要比遍历聚簇索引树的成本要小的多（聚簇索引树包含一些隐藏列，扫描的数据页多一些

* count性能

  * count(*) = count(1) > count(主键) > count(字段)

  * count(字段):**不为 NULL 的记录有多少个**

  * > InnoDB handles SELECT COUNT(`\*`) and SELECT COUNT(`1`) operations in the same way. There is no performance difference.

  * 加速count

    * 模糊：show table status
    * 精确：额外维护这个计数表（框架提供能力，无侵入

* 选择B+树而不选择B树

  * B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「**矮胖**」，查询底层节点的磁盘 I/O次数会更少。
  * B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
  * B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

* 大事务的危害

  * 锁定太多的数据，造成大量的阻塞和锁超时。
  * 回滚所需要的时间比较长。
  * 执行时间长，容易造成主从延迟。

* 优化limit分页：

  * limit l offset o：会将0～l+o行所有的数据返回给server层，再由server层返回第l~o行数据

  * 尽可能的使用覆盖索引扫描

    将

    > **SELECT** film_id,description **FROM** film **ORDER** **BY** title **LIMIT** 50,5; 

    改为

    > **SELECT** film.film_id,film.description 
    > **FROM** film **INNER** **JOIN** ( 
    >   **SELECT** film_id **FROM** film **ORDER** **BY** title **LIMIT** 50,5 
    > ) **AS** tmp **USING**(film_id); 

* innodb使用b+ tree，不使用跳表原因：https://juejin.cn/post/7106131535857713160

### Go

* Type、Value和Kind

* gmp：https://go.cyub.vip/gmp/gmp-model.html

* 协程

  * 协程必须与内核级线程绑定之后才能执行
  * 线程由 CPU 调度是抢占式的，协程由用户态调度是协作式的，一个协程让出 CPU 后，才执行下一个协程

* 协程的优点

  * 相比线程，其启动的代价很小，以很小栈空间启动（2Kb左右）
  * 能够动态地伸缩栈的大小，最大可以支持到Gb级别
  * 工作在用户态，切换成很小
  * 与线程关系是n:m，即可以在n个系统线程上多工调度m个Goroutine

* 内核级线程的优点

  - 在多处理器系统中，内核能够并行执行同一进程内的多个线程
  - 如果进程中的一个线程被阻塞，不会阻塞其他线程，是能够切换同一进程内的其他线程继续执行
  - 当一个线程阻塞时，内核根据选择可以运行另一个进程的线程，而用户空间实现的线程中，运行时系统始终运行自己进程中的线程

  缺点：

  * 线程的创建与删除都需要CPU参与，成本大
  * 数量受内核限制

* 用户级线程的优点：

  - 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多, 因为保存线程状态的过程和调用程序都只是本地过程
  - 线程能够利用的表空间和堆栈空间比内核级线程多

  缺点：

  - 线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程, 因此同一进程中只能同时有一个线程在运行
  - 资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用

* G-M-P分别代表：

  - G - Goroutine，Go协程，是参与调度与执行的最小单位
  - M - Machine，指的是系统级线程
  - P - Processor，指的是逻辑处理器，P关联了的本地可运行G的队列(也称为LRQ)。

* 当G因系统调用(syscall)阻塞时会阻塞M，此时P会和M解绑即**hand off**，并寻找新的idle的M，若没有idle的M就会新建一个M。

* 当G因channel或者network I/O阻塞时，不会阻塞M，M会寻找其他runnable的G；当阻塞的G恢复后会重新进入runnable进入P队列等待执行(流程5.3)

* 在任一时刻，只能最多有和逻辑CPU数目（P）一样多的协程在同时执行

* defer：延迟调用队列（一个后进先出队列）

  * 一个延迟调用的**实参**是在此**调用**对应的延迟调用语句被执行时被估值的
  * 一个匿名函数体内的表达式是在此**函数**被执行的时候才会被逐渐估值的

* panic和recover

* 一些致命性错误不属于恐慌，比如栈溢出和内存不足，不能被恢复。它们一旦产生，程序将崩溃。

* 通道

  * **不要让计算通过共享内存来通讯，而应该让它们通过通讯来共享内存**
  * 关闭一个nil通道或者一个已经关闭的通道将产生一个恐慌。
  * 向一个已关闭的通道发送数据也将导致一个恐慌。
  * 向一个nil通道发送数据或者从一个nil通道接收数据将使当前协程永久阻塞。
  * 一个通道内部维护了三个队列
    * 接收数据协程队列
    * 发送数据协程队列
    * 数据缓冲队列



### Web

* 粘性session和非粘性session
* 一致性hash：负载均衡，解决数据迁移，虚拟节点提高均衡性



### 计算机网络

#### HTTP

* HTTPS 是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层
  * 信息加密：混合加密的⽅式实现信息的机密性
  * 校验机制：摘要算法的⽅式来实现完整性
  * 身份证书：将服务器公钥放⼊到数字证书中
* HTTP演变经过
  * 1.0 --> 1.1
    * 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
    *  ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以 减少整体的响应时间。
    * 问题：队头阻塞：https://zhuanlan.zhihu.com/p/330300133
      * 在切换到发送新资源之前，必须**完整地**传输资源响应。如果前面的资源创建缓慢（例如，从数据库查询动态生成的`index.html`）或者，如果前面的资源很大。这些问题可能会引起队头阻塞问题。
  * 1.1 --> 2
    * 头部压缩
    * 二进制格式
    * 数据流
      * 引入“帧”（frames）标识每个资源块属于哪个“流”（stream），多路复用解决**应用层的队头阻塞**问题
    * 服务器推送
    * 问题：tcp的某个包的丢失可能导致所有的 HTTP 请求都必须等 待这个丢了的包被重传回来。
  * 2 --> 3
    * Tcp --> udp 解决**传输层的队头阻塞**问题

#### TCP

* TCP 和 UDP 区别： 
  * 连接 
    * TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。 
    * UDP 是不需要连接，即刻传输数据。
  * 服务对象 
    * TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。
    *  UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信 
  * 可靠性 
    * TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不重复、按需到达。
    *  UDP 是尽最⼤努⼒交付，不保证可靠交付数据。 
  * 拥塞控制、流量控制 
    * TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 
    * UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率。
  * ⾸部开销 
    * TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 20 个字节，如果使⽤了「选项」 字段则会变⻓的。 
    * UDP ⾸部只有 8 个字节，并且是固定不变的，开销较⼩。 6. 传输⽅式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。
  * 分⽚不同
    *  TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。 
    * UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着 再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样 传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

* 重传机制

  * 超时重传
  * 快速重传
  * SACK：Selective Acknowledgment 选择性确认

* 流量控制：双端的收发能力

  * 滑动窗口
  * 窗口探测
  * 糊涂窗⼝综合症
    * Nagle 算法，让发送⽅避免发送⼩数据
    * 窗口探测

* 拥塞控制：网络情况

  * 拥塞窗口
  * 慢启动 
  * 拥塞避免 
  * 拥塞发⽣ 
    * 超时重传
    * 快速重传：当发送⽅收到 3 个重复 ACK 时，就会触发快速重传，⽴刻重发丢失数据包

* 连接时延：在第三次握⼿发起 HTTP GET 请求，需要 2 个 RTT 的时延

* MSS

  * MSS选项用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度。
  * 在分⽚传输中，⼀旦某个分⽚丢失，则会造成整个 IP 数据报作废，所以 TCP 引⼊了 MSS 也就是在 TCP 层进⾏ 分⽚不由 IP 层分⽚（否则重传效率低），那么对于 UDP 我们尽量不要发送⼀个⼤于 MTU 的数据报⽂。

* 三次握手

  * ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态

  * 客户端随机初始化序号（ client_isn ），同时把 SYN 标志 位置为 1，之后客户端处于 SYN-SENT 状态。

  * 服务端收到客户端的 SYN 报⽂后，⾸先服务端也随机初始化⾃⼰的序号（ server_isn ），其次把 TCP ⾸部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN 和 ACK 标志位置为 1 ，最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于 SYNRCVD 状态

  * 客户端收到服务端报⽂后，回应最后⼀个应答报⽂，⾸先该应答报⽂ TCP ⾸部 ACK 标志位 置为 1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报⽂发送给服务端，这次报⽂可以携带客 户到服务器的数据，之后客户端处于 ESTABLISHED 状态。

  * 服务器收到客户端的应答报⽂后，也进⼊ ESTABLISHED 状态。

  * 为什么三次握手

    * **三次握⼿保证双⽅具有接收和发送的能⼒**

    * 三次握⼿才可以阻⽌重复历史连接的初始化（主要原因）

      > The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.

      如果是两次握⼿连接，就不能判断当前连接是否是历史连接，三次握⼿则可以在客户端（发送⽅）准备发送第三次 报⽂时，客户端因有⾜够的上下⽂来判断当前连接是否是历史连接（包含随机序列号的功劳

    *  三次握⼿才可以同步双⽅的初始序列号 

    * 三次握⼿才可以避免资源浪费

  * 序列号随机

    * 客户端随机原因：避免历史重复连接
    * 服务端随机原因：避免黑客冒充  https://www.cnblogs.com/Brake/p/13557055.html

  * IP 层会分⽚，为什么 TCP 层还需要 MSS 呢？

    * 么当如果⼀个 IP 分⽚丢失，整个 IP 报⽂的所有分⽚都得重传（IP不保证数据完整性），效率不高

  * 握手失败

    * 第三次失败：服务端在第二次握手失败后超时重试不行后断开连接，客户端连接则是处于established状态，直至主动发送数据，超时重试不行后断开（另外有保活机制）

  * 半连接队列，也称 SYN 队列

  * 全连接队列，也称 accepet 队列

  * 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到**半连接队列**，并向客户端响应 SYN+ACK，接着客 户端会返回 ACK，服务端收到第三次握⼿的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连 接，并将其添加到 **全连接**队列，等待进程调⽤ accept 函数时把连接取出来

  *  SYN 洪泛：

    * 客户端不回复第三次握⼿ ACK，这样就 会使得服务端有⼤量的处于 SYN_RECV 状态的 TCP 连接
    * 解决：syncookies，第二次握手期间连接不进入半连接队列，而是返回客户端cookie，在第三次握手时通过校验该cookie来完成握手连接

* 四次挥手

  * 客户端打算关闭连接，此时会发送⼀个 TCP ⾸部 FIN 标志位被置为 1 的报⽂，也即 FIN 报⽂，之后客 户端进⼊ FIN_WAIT_1 状态。 
  * 服务端收到该报⽂后，就向客户端发送 ACK 应答报⽂，接着服务端进⼊ CLOSED_WAIT 状态。 
  * 客户端收到服务端的 ACK 应答报⽂后，之后进⼊ FIN_WAIT_2 状态。 
  * 等待服务端处理完数据后，也向客户端发送 FIN 报⽂，之后服务端进⼊ LAST_ACK 状态。 
  * 客户端收到服务端的 FIN 报⽂后，回⼀个 ACK 应答报⽂，之后进⼊ **TIME_WAIT** 状态 服务器收到了 ACK 应答报⽂后，就进⼊了 CLOSED 状态，⾄此服务端已经完成连接的关闭。 
  * 客户端在经过 2MSL ⼀段时间后，⾃动进⼊ CLOSED 状态，⾄此客户端也完成连接的关闭。
  * 为什么 TIME_WAIT 等待的时间是 2MSL？
    * MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间
    * **防⽌具有相同「四元组」的「旧」数据包被收到**； 2MSL⾜以让两个⽅向上的数据包都被丢弃，使得原来 连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。
    * **保证「被动关闭连接」的⼀⽅能被正确的关闭**，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关 闭；
  * TIME_WAIT 过多的危害：如果发起连接⼀⽅的 TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接。

* TCP保活机制

#### IP

* 源IP地址和⽬标IP地址在传输过程中是不会变化的，只有源 MAC 地址和⽬标 MAC ⼀直在变化
* 当主机号全为 1 时，就表示该⽹络的⼴播地址
* CIDR：32 ⽐特的 IP 地址被划分为两部分，前⾯是⽹络号，后⾯是主机号
* IPv4 VS IPv6
  * 取消了⾸部校验和字段
  * 取消了分⽚/重新组装相关字段
  * 取消选项字段
* DNS协议
  * 根 DNS 服务器、 顶级域 DNS 服务器（com）、 权威 DNS 服务器（server.com）、本地 DNS 服务器
* ARP协议
  * 主机会通过⼴播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的⽬标 IP 地址与⾃⼰的 IP 地址⼀致，那么这个设备就将⾃⼰的 MAC 地址塞⼊ ARP 响应包返回给主机。
* DHCP协议
  * 全程使⽤ UDP ⼴播通信
  * DHCP 中继代理：对不同⽹段的 IP 地址分配也 可以由⼀个 DHCP 服务器统⼀进⾏管理
* NAT
  * 不同私有 IP 地址转换 IP 地址为同一公有地址 ，但是以不同的端⼝号作为区分
  * 问题：外部⽆法主动与 NAT 内部服务器建⽴连接
  * 解决： NAT 穿透技术
* ICMP
  * ICMP 报⽂是封装在 IP 包⾥⾯，它⼯作在⽹络层，是 IP 协议的助⼿
  * 主要的功能包括：确认 IP 包是否成功送达⽬标地址、报告发送过程中 IP 包被废弃的原因和改善⽹络设置 等
  * ping（echo request、echo reply

#### 数据链路层

* MTU：以太网1500字节

#### 「当键⼊⽹址后，到⽹⻚显示，其间发⽣了什么」

1. 解析 URL
2. 查询服务器域名对应的 IP 地址，⽣产 HTTP 请求信息
3. TCP三次握手
   1. IP层（路由表：一个机子一张，不是一个网卡一张
   2. 数据链路层：Mac地址（ARP协议
   3. 物理层：网卡
4. 发送HTTP请求
5. 如果 HTTP 请求消息⽐较⻓，超过了 MSS 的⻓度，这时 TCP 就需要把 HTTP 的数据拆解成⼀块块的数据发送， ⽽不是⼀次性发送所有数据。

#### 网络设备

* 交换机：数据链路层设备
  * 交换机的端⼝不具有 MAC 地址
* 路由器：IP层设备
  * 路由器的各个端⼝都具有 MAC 地址和 IP 地址

### Redis

* 项目：直播流热度统计
  * 使用zset
    * key：streamID
    * value：userID 
    * weight：timestamp
  * 问题：大key导致负载不均衡，单机容量不够（无法靠横向扩展解决
  * 不使用 流 --> 人数 的原因
    * 减少代码侵入
    * 避免额外的数据同步
    * 本地调用优于远程调用
  * 解决：分片
  * 又问题：分片导致查询时间*n
  * 解决：本地缓存，本地淘汰时使用singleflight（src/internal/singleflight 组提交，防止穿透、降延时
  * 又问题：全局锁，影响并发
  * 解决：1. 业务层分shard 2.放弃singleflight（延时增加，此处不考虑redis的承受能力
  * 又问题：固定分片数导致冷流不必要分片，徒增redis请求
  * 解决：动态分片，一致性hash，减少影响



### 缓存和数据库的一致性

* 高一致性：分布式事务

* 低一致性：先更新数据库再删缓存
  * 删缓存操作可以异步（交给消息队列，超时重试）
  * 可让缓存监听binlog（让redis把自己伪装成一个 MySQL 的从节点



### 线上问题排查

* log文件 grep -w panic -rn ./
* Systemctl status 服务名、journalctl -u 服务名
* dmesg ：输出内核环形缓冲区信息。内核环形缓冲区是物理内存的一部分，用于保存内核的日志消息。它具有固定的大小，这意味着一旦缓冲区已满，较旧的日志记录将被覆盖。
